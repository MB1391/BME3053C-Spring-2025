{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97c2a9d",
   "metadata": {},
   "source": [
    "# ðŸ©º AI Powered Leukemia Detection Model\n",
    "This notebook implements an AI-powered model to detect leukemia using machine learning techniques. It includes data preprocessing, model training, evaluation, and prediction functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f1e00",
   "metadata": {},
   "source": [
    "# Standard Imports\n",
    "This cell imports all the necessary libraries and modules required for data processing, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8190efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports - DO NOT CHANGE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed5d61",
   "metadata": {},
   "source": [
    "# Leukemia Detection Model Class\n",
    "This cell defines the `LeukemiaDetectionModel` class, which includes methods for loading data, preprocessing, training models, and making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd34f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeukemiaDetectionModel:\n",
    "    def __init__(self, target_column=None, id_column=None):\n",
    "        \"\"\"Initialize model with optional column detection\"\"\"\n",
    "        self.target_column = target_column\n",
    "        self.id_column = id_column\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.trained_models = None\n",
    "\n",
    "    def auto_detect_columns(self):\n",
    "        \"\"\"Automatically detect target and ID columns based on keywords\"\"\"\n",
    "        if self.target_column is None:\n",
    "            for col in self.df.columns:\n",
    "                if 'leukemia' in col.lower() and 'status' in col.lower():\n",
    "                    self.target_column = col\n",
    "                    print(f\"Detected target column: {self.target_column}\")\n",
    "                    break\n",
    "            if self.target_column is None:\n",
    "                raise ValueError(\"Unable to detect target column related to leukemia status. Please specify it explicitly.\")\n",
    "\n",
    "        if self.id_column is None:\n",
    "            for col in self.df.columns:\n",
    "                if 'id' in col.lower():\n",
    "                    self.id_column = col\n",
    "                    print(f\"Detected ID column: {self.id_column}\")\n",
    "                    break\n",
    "\n",
    "    def load_data(self, data_path=None):\n",
    "        \"\"\"Load data and detect columns if necessary\"\"\"\n",
    "        if data_path is not None:\n",
    "            if data_path.endswith('.csv'):\n",
    "                self.df = pd.read_csv(data_path)\n",
    "            elif data_path.endswith('.xlsx'):\n",
    "                self.df = pd.read_excel(data_path)\n",
    "            elif data_path.endswith('.json'):\n",
    "                self.df = pd.read_json(data_path)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format. Please provide a CSV, Excel, or JSON file.\")\n",
    "        else:\n",
    "            raise ValueError(\"data_path must be provided\")\n",
    "\n",
    "        # Automatically detect target and ID columns if not provided\n",
    "        self.auto_detect_columns()\n",
    "\n",
    "        # Handle missing values\n",
    "        if self.df.isnull().sum().sum() > 0:\n",
    "            self.df.fillna(self.df.mean(numeric_only=True), inplace=True)\n",
    "            self.df.fillna('Unknown', inplace=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def explore_data(self, max_plots=6):\n",
    "        \"\"\"Explore data with automatic feature type detection\"\"\"\n",
    "        print(\"\\nClass Distribution for\", self.target_column)\n",
    "        print(self.df[self.target_column].value_counts(normalize=True))\n",
    "        \n",
    "        # Convert target to numerical if it's categorical\n",
    "        if self.df[self.target_column].dtype == 'object':\n",
    "            target_encoder = LabelEncoder()\n",
    "            self.df[self.target_column] = target_encoder.fit_transform(self.df[self.target_column])\n",
    "            print(\"\\nConverted target values:\")\n",
    "            for i, label in enumerate(target_encoder.classes_):\n",
    "                print(f\"{label} -> {i}\")\n",
    "        \n",
    "        # Automatically identify numerical and categorical columns\n",
    "        self.numerical_features = self.df.select_dtypes(\n",
    "            include=['int64', 'float64']).columns.tolist()\n",
    "        self.categorical_features = self.df.select_dtypes(\n",
    "            include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        # Remove target and ID columns from features\n",
    "        for col in [self.target_column, self.id_column]:\n",
    "            if col in self.numerical_features:\n",
    "                self.numerical_features.remove(col)\n",
    "            if col in self.categorical_features:\n",
    "                self.categorical_features.remove(col)\n",
    "        \n",
    "        print(\"\\nNumerical features:\", self.numerical_features)\n",
    "        print(\"Categorical features:\", self.categorical_features)\n",
    "        \n",
    "        # Plot distributions of numerical features\n",
    "        if len(self.numerical_features) > 0:\n",
    "            n_plots = min(len(self.numerical_features), max_plots)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            for i, feature in enumerate(self.numerical_features[:n_plots], 1):\n",
    "                plt.subplot(2, 3, i)\n",
    "                sns.histplot(data=self.df, x=feature, hue=self.target_column, multiple=\"stack\")\n",
    "                plt.title(f'Distribution of {feature}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Correlation matrix\n",
    "        if len(self.numerical_features) > 0:\n",
    "            numerical_df = self.df[self.numerical_features + [self.target_column]]\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "            plt.title('Correlation Matrix')\n",
    "            plt.show()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def preprocess_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"Preprocess data with automatic handling of different data types\"\"\"\n",
    "        df_processed = self.df.copy()\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        for feature in self.categorical_features:\n",
    "            self.label_encoders[feature] = LabelEncoder()\n",
    "            df_processed[feature] = self.label_encoders[feature].fit_transform(df_processed[feature])\n",
    "        \n",
    "        # Prepare features and target\n",
    "        exclude_cols = [col for col in [self.target_column, self.id_column] if col is not None]\n",
    "        X = df_processed.drop(exclude_cols, axis=1).values\n",
    "        y = df_processed[self.target_column].values\n",
    "        \n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Scale the features\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def select_features(self, n_features=10):\n",
    "        \"\"\"Select the top n most important features using Random Forest feature importance.\"\"\"\n",
    "        if not hasattr(self, 'X_train_scaled') or not hasattr(self, 'y_train'):\n",
    "            raise ValueError(\"Data must be preprocessed before feature selection.\")\n",
    "\n",
    "        # Train a Random Forest model to get feature importances\n",
    "        temp_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        temp_model.fit(self.X_train_scaled, self.y_train)\n",
    "\n",
    "        # Get feature importances and sort them\n",
    "        importances = temp_model.feature_importances_\n",
    "        feature_names = [col for col in self.df.columns if col not in [self.target_column, self.id_column]]\n",
    "        feature_importance = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top n features\n",
    "        self.selected_features = [feature[0] for feature in feature_importance[:n_features]]\n",
    "        print(f\"Selected top {n_features} features: {self.selected_features}\")\n",
    "\n",
    "        # Filter training and test data to include only selected features\n",
    "        selected_indices = [feature_names.index(feature) for feature in self.selected_features]\n",
    "        self.X_train = self.X_train[:, selected_indices]\n",
    "        self.X_test = self.X_test[:, selected_indices]\n",
    "\n",
    "        # Refit the scaler on the selected features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"Train multiple models with progress updates\"\"\"\n",
    "        self.models = {\n",
    "            'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        \n",
    "        self.trained_models = {}\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "            model.fit(self.X_train_scaled, self.y_train)\n",
    "            train_score = model.score(self.X_train_scaled, self.y_train)\n",
    "            print(f\"{name} training accuracy: {train_score:.4f}\")\n",
    "            self.trained_models[name] = model\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate models with detailed metrics\"\"\"\n",
    "        self.results = {}\n",
    "        \n",
    "        for name, model in self.trained_models.items():\n",
    "            print(f\"\\nEvaluating {name}...\")\n",
    "            y_pred = model.predict(self.X_test_scaled)\n",
    "            y_pred_proba = model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "            \n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            self.results[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'auc': roc_auc,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba\n",
    "            }\n",
    "\n",
    "        # Plot ROC curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for name, metrics in self.results.items():\n",
    "            plt.plot(metrics['fpr'], metrics['tpr'], \n",
    "                    label=f'{name} (AUC = {metrics[\"auc\"]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves for All Models')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Print detailed classification reports\n",
    "        for name, metrics in self.results.items():\n",
    "            print(f\"\\nClassification Report for {name}:\")\n",
    "            print(classification_report(self.y_test, metrics['predictions']))\n",
    "\n",
    "        # Compare model accuracies\n",
    "        accuracies = {name: metrics['accuracy'] \n",
    "                     for name, metrics in self.results.items()}\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(accuracies.keys(), accuracies.values())\n",
    "        plt.title('Model Accuracy Comparison')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _load_data_from_path(self, data_path):\n",
    "        \"\"\"Helper method to load data from a file path.\"\"\"\n",
    "        if data_path.endswith('.csv'):\n",
    "            return pd.read_csv(data_path)\n",
    "        elif data_path.endswith('.xlsx'):\n",
    "            return pd.read_excel(data_path)\n",
    "        elif data_path.endswith('.json'):\n",
    "            return pd.read_json(data_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Please provide a CSV, Excel, or JSON file.\")\n",
    "\n",
    "    def predict_unlabeled_data(self, user_input):\n",
    "        \"\"\"Predict leukemia status for user-provided input.\"\"\"\n",
    "        # Align user input with training features\n",
    "        aligned_input = [user_input[feature] for feature in self.selected_features]\n",
    "\n",
    "        # Scale numerical features\n",
    "        aligned_input_scaled = self.scaler.transform([aligned_input])\n",
    "\n",
    "        # Use the trained model to predict\n",
    "        predictions = {name: model.predict(aligned_input_scaled)[0] for name, model in self.trained_models.items()}\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d52b2d",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "This cell adds a feature selection step to the model. It uses feature importance from a Random Forest model to select the most relevant features for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c68ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeukemiaDetectionModel:\n",
    "    def select_features(self, n_features=10):\n",
    "        \"\"\"Select the top n most important features using Random Forest feature importance.\"\"\"\n",
    "        if not hasattr(self, 'X_train_scaled') or not hasattr(self, 'y_train'):\n",
    "            raise ValueError(\"Data must be preprocessed before feature selection.\")\n",
    "\n",
    "        # Train a Random Forest model to get feature importances\n",
    "        temp_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        temp_model.fit(self.X_train_scaled, self.y_train)\n",
    "\n",
    "        # Get feature importances and sort them\n",
    "        importances = temp_model.feature_importances_\n",
    "        feature_names = [col for col in self.df.columns if col not in [self.target_column, self.id_column]]\n",
    "        feature_importance = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top n features\n",
    "        self.selected_features = [feature[0] for feature in feature_importance[:n_features]]\n",
    "        print(f\"Selected top {n_features} features: {self.selected_features}\")\n",
    "\n",
    "        # Filter training and test data to include only selected features\n",
    "        selected_indices = [feature_names.index(feature) for feature in self.selected_features]\n",
    "        self.X_train = self.X_train[:, selected_indices]\n",
    "        self.X_test = self.X_test[:, selected_indices]\n",
    "\n",
    "        # Refit the scaler on the selected features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffbd9cc",
   "metadata": {},
   "source": [
    "# Run the Leukemia Detection Model with Feature Selection\n",
    "This cell creates an instance of the `LeukemiaDetectionModel` class, loads the dataset, explores the data, preprocesses it, selects the top features, trains the models, and evaluates their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run the model with automatic column detection and feature selection\n",
    "model = LeukemiaDetectionModel()\n",
    "\n",
    "model.load_data(\n",
    "    data_path='biased_leukemia_dataset.csv'  # Replace with your data file path\n",
    ")\n",
    "\n",
    "model.explore_data()\n",
    "\n",
    "model.preprocess_data(test_size=0.2)\n",
    "\n",
    "# Select the top 10 features\n",
    "model.select_features(n_features=10)\n",
    "\n",
    "model.train_models()\n",
    "\n",
    "model.evaluate_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31302a5d",
   "metadata": {},
   "source": [
    "# Predict Leukemia Status with Selected Features\n",
    "This cell allows the user to input data for only the selected features and predicts whether the person has leukemia or not using the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4710041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please provide the following inputs for the selected features:\n",
      "\n",
      "Prediction from Logistic Regression: Does Not Have Leukemia\n",
      "\n",
      "Prediction from Random Forest: Does Not Have Leukemia\n",
      "\n",
      "Prediction from Logistic Regression: Does Not Have Leukemia\n",
      "\n",
      "Prediction from Random Forest: Does Not Have Leukemia\n"
     ]
    }
   ],
   "source": [
    "# Predict leukemia status for a new dataset using user input with selected features\n",
    "def get_user_input():\n",
    "    \"\"\"Prompt user for input with feature ranges and return a dictionary.\"\"\"\n",
    "    print(\"\\nPlease provide the following inputs for the selected features:\")\n",
    "    user_data = {}\n",
    "    for feature in model.selected_features:\n",
    "        if feature in model.numerical_features:\n",
    "            min_val = model.df[feature].min()\n",
    "            max_val = model.df[feature].max()\n",
    "            value = float(input(f\"Enter value for {feature} (Range [{min_val}, {max_val}]): \"))\n",
    "        elif feature in model.categorical_features:\n",
    "            unique_vals = model.df[feature].unique()\n",
    "            value = input(f\"Enter value for {feature} (Possible values {list(unique_vals)}): \")\n",
    "            # Encode categorical input using the label encoder\n",
    "            if feature in model.label_encoders:\n",
    "                value = model.label_encoders[feature].transform([value])[0]\n",
    "        user_data[feature] = value\n",
    "    return user_data\n",
    "\n",
    "# Get user input and make predictions\n",
    "user_input = get_user_input()\n",
    "\n",
    "# Align user input with selected features\n",
    "aligned_input = [user_input[feature] for feature in model.selected_features]\n",
    "\n",
    "# Scale the input and make predictions\n",
    "aligned_input_scaled = model.scaler.transform([aligned_input])\n",
    "predictions = {name: model.predict(aligned_input_scaled)[0] for name, model in model.trained_models.items()}\n",
    "\n",
    "# Convert predictions to human-readable labels\n",
    "for model_name, prediction in predictions.items():\n",
    "    result = \"Has Leukemia\" if prediction == 1 else \"Does Not Have Leukemia\"\n",
    "    print(f\"\\nPrediction from {model_name}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
